import streamlit as st
from llama_index.core import StorageContext, load_index_from_storage, VectorStoreIndex, SimpleDirectoryReader, \
    ChatPromptTemplate
from llama_index.llms.huggingface import HuggingFaceInferenceAPI
from dotenv import load_dotenv
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings
import os
import base64
import json
from datetime import datetime
import random
import learning_agent
# ç°åœ¨æˆ‘ç›´æ¥æ‰¾äº†ä¸€ä¸ªæ–‡ä»¶é—®ç­”çš„æ¨¡æ¿ï¼ŒåæœŸåªéœ€è¦æŠŠæˆ‘ä»¬çš„pipeline å°è£…æˆå‡½æ•°ï¼Œå³å¯æ‰§è¡Œç”¨æˆ·è¾“å…¥å¯¹åº”è¾“å‡º
# ç›®å‰å¯ä»¥åšçš„UIè®¾è®¡ï¼š
# ç»§ç»­å®Œå–„è¯¾ä»¶å›ç­”chatbot
# è®¾è®¡å¤ä¹ chatbotçš„äº§å“å±•ç¤ºå½¢å¼  âˆš
# å°†ä¸¤è€…æ”¾åœ¨ä¸€ä¸ªç½‘ç«™ (ä¾§è¾¹æ  or å…¶ä»–æ–¹æ³•)  âˆš
# ç½‘ç«™é…è‰² å¯å‚è€ƒè¿™ä¸ªç½‘ç«™ï¼šhttps://coolors.co/262322-63372c-c97d60-ffbcb5-f2e5d7
# ä¿®æ”¹streamlité…è‰²æ–¹æ³•ï¼šhttps://blog.csdn.net/BigDataPlayer/article/details/128962594
# æœ¬åœ°è°ƒè¯•ï¼Œå‘½ä»¤è¡Œè¿›å…¥ç›¸åº”è·¯å¾„æ‰§è¡Œï¼š streamlit run app.py

# æ›´æ–°ï¼šç›®å‰å¤ä¹ æ¨¡å—çš„å±•ç¤ºå·²ç»å®Œæˆï¼Œä½†è¿˜å‰©ç›¸å…³é—®é¢˜ç”Ÿæˆéœ€å¯¹æ¥ï¼ŒåŒ…æ‹¬èŠå¤©è®°å½•å­˜å‚¨ä¹Ÿå·²ç»å®Œæˆï¼Œç­‰å¾…æ¥å£å®Œæˆæœ€ç»ˆè°ƒè¯•



@st.cache_data()
def get_base64_of_bin_file(png_file):
    with open(png_file, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()


def build_markup_for_logo(
    png_file,
    background_position="50% 10%",
    margin_top="5%",
    image_width="80%",
    image_height="",
):
    binary_string = get_base64_of_bin_file(png_file)
    return """
            <style>
                [data-testid="stSidebarNav"] {
                    background-image: url("data:image/png;base64,%s");
                    background-repeat: no-repeat;
                    background-position: %s;
                    margin-top: %s;
                    background-size: %s %s;
                }
            </style>
            """ % (
        binary_string,
        background_position,
        margin_top,
        image_width,
        image_height,
    )


def add_logo(png_file):
    logo_markup = build_markup_for_logo(png_file)
    st.markdown(
        logo_markup,
        unsafe_allow_html=True,
    )

add_logo("image/icon.png")






# Define the directory for persistent storage and data
PERSIST_DIR = "./db"
DATA_DIR = "data"
CHAT_HISTORY_DIR = "chat_history"  # New directory for chat history

# Ensure data directory exists
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(PERSIST_DIR, exist_ok=True)
os.makedirs(CHAT_HISTORY_DIR, exist_ok=True)  # Ensure chat history directory exists


def displayPDF(file):
    with open(file, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
    pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="600" type="application/pdf"></iframe>'
    st.markdown(pdf_display, unsafe_allow_html=True)


if 'messages' not in st.session_state:
    st.session_state.messages = [
        {'role': 'assistant', "content": 'Hello! Upload a PDF and ask me anything about its content.'}]

if 'all_QA' not in st.session_state:
    st.session_state.all_QA = []

if 'qa_id' not in st.session_state:
    st.session_state.qa_id = 0

if 'conversation' not in st.session_state:
    st.session_state.conversation = 'conversation'

#
# # éšæœºé€‰æ‹©ä¸€ä¸ªQAæ–‡ä»¶ï¼Œç„¶åä»è¯¥æ–‡ä»¶ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªQAå¯¹è¯
# def get_random_qa_pair():
#     chat_files = [f for f in os.listdir(CHAT_HISTORY_DIR) if f.endswith(".json")]
#
#     if not chat_files:
#         return None, None  # å¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œè¿”å›None
#
#     # ä»ç›®å½•ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ–‡ä»¶
#     selected_file = random.choice(chat_files)
#
#     # è¯»å–æ–‡ä»¶å¹¶æå–æ‰€æœ‰èŠå¤©è®°å½•
#     with open(f"{CHAT_HISTORY_DIR}/{selected_file}", 'r') as file:
#         chat_data = json.load(file)
#
#     # ç¡®ä¿æ–‡ä»¶ä¸­æœ‰å†…å®¹
#     if len(chat_data) > 0:
#         # ä»èŠå¤©è®°å½•ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªQAå¯¹
#         random_index = random.randint(0, len(chat_data) - 1)
#         selected_qa = chat_data[random_index]
#         return selected_qa['user'], selected_qa['answer']
#
#     return None, None  # å¦‚æœæ–‡ä»¶ä¸­æ²¡æœ‰èŠå¤©è®°å½•


#image icon
icon_path = r"image\icon.png"
# Streamlit app initialization
st.title("Chat with your PDFğŸ“„")
# st.markdown("Built by [Qichenâ¤ï¸]()")
st.markdown("chat hereğŸ‘‡")

#
# # ä¾§è¾¹æ 
# with st.sidebar:
#     st.image(icon_path, use_column_width=True)
#     st.title("Menu:")
#     uploaded_file = st.file_uploader("Upload your PDF Files and Click on the Submit & Process Button")
#     if st.button("Submit & Process"):
#         with st.spinner("Processing..."):
#             filepath = "data/saved_pdf.pdf"
#             with open(filepath, "wb") as f:
#                 f.write(uploaded_file.getbuffer())
#             # displayPDF(filepath)  # Display the uploaded PDF
#
#             learning_agent.ingest_and_index_with_pdf_reader(filepath, PERSIST_DIR)
#             st.success("Upload file successfully!")
#
# # New code from here
#     if st.button("Review Mode"):
#         # è·å–éšæœºQAå¯¹
#         user, answer = get_random_qa_pair()
#         print(user, answer)
#
#         if user is not None and answer is not None:
#             # å­˜å‚¨åˆ°ä¼šè¯çŠ¶æ€ä¸­
#             st.session_state['current_qa_pair'] = {'user': user, 'answer': answer}
#             st.rerun()  # è§¦å‘åˆ·æ–°ä»¥æ›´æ–°æ˜¾ç¤º
#         else:
#             st.write("No QA pairs found.")
#
# # If Review Mode is activated and we have a QA pair
# if 'current_qa_pair' in st.session_state:
#     # Refresh button to get a new random QA pair
#     if st.sidebar.button("Refresh QA"):
#         # è·å–æ–°çš„éšæœºQAå¯¹
#         user, answer = get_random_qa_pair()
#
#         if user is not None and answer is not None:
#             st.session_state['current_qa_pair'] = {'user': user, 'answer': answer}
#             st.rerun()  # è§¦å‘åˆ·æ–°
#         else:
#             st.sidebar.write("No QA pairs found.")
#
#     st.sidebar.write("Random QA Pair:")
#     qa_pair = st.session_state['current_qa_pair']
#     user = qa_pair.get("user", "Unknown")
#     answer = qa_pair.get("answer", "No answer")
#     st.sidebar.write(f"User: {user}")
#     st.sidebar.write(f"Answer: {answer}")
if "visibility" not in st.session_state:
    st.session_state.visibility = "visible"
    st.session_state.disabled = False

# ä¾§è¾¹æ 
with st.sidebar:
    # è®¾ç½®å›¾ç‰‡å’Œæ ‡é¢˜
    st.title("Menu:")

    # ä¸Šä¼ æ–‡ä»¶
    uploaded_file = st.file_uploader("Upload your PDF Files and Click on the Submit & Process Button")

    # æäº¤å¹¶å¤„ç†æ–‡ä»¶
    if st.button("Submit & Process", use_container_width=True):
        with st.spinner("Processing..."):
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            filepath = "data/saved_pdf.pdf"
            with open(filepath, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # å¤„ç†æ–‡ä»¶
            learning_agent.ingest_and_index_with_pdf_reader(filepath, PERSIST_DIR)
            st.success("Upload file successfully!")

    conversation = st.sidebar.text_input("Enter your topic:")
    if conversation:
        st.sidebar.write("Your conversation will be saved as : ", conversation)
        st.session_state.conversation = conversation

# Save chat history
def auto_save_conversation(messages, name):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"chat_history/{name}.json"
    with open(filename, 'w') as file:
        json.dump(messages, file, indent=4)
    return filename

user_prompt = st.chat_input("Ask me anything about the content of the PDF:")
if user_prompt:
    retriver = learning_agent.retriever_rerank(PERSIST_DIR)
    st.session_state.messages.append({'role': 'user', "content": user_prompt})
    response, _ = learning_agent.query_normal(retriver, user_prompt)
    # st.session_state.messages.append({'role': 'assistant', "content": response.response})
    # streaming
    st.session_state.messages.append({'role': 'assistant', "content": response.response_txt})
    st.session_state.all_QA.append({
        "id": st.session_state.qa_id,
        "user": user_prompt,
        "answer": response.response_txt
    })
    st.session_state.qa_id += 1
    # Auto save conversation
    print(st.session_state.conversation)
    filename = auto_save_conversation(st.session_state.all_QA, st.session_state.conversation)
    st.success(f"Conversation auto-saved to {filename}")


for message in st.session_state.messages:
    with st.chat_message(message['role']):
        st.write(message['content'])


